% Uncomment below for AASTEX
\documentclass[preprint]{aastex}
% Uncomment below for EMULATEAPJ
%\documentclass[iop]{emulateapj}
\usepackage{url}
\usepackage{color}
\shorttitle{gPhoton}
\shortauthors{Chase Million et al.}
\begin{document}
\title{gPhoton: A Time-Tagged Database of GALEX Photon Events}

\author{
Chase Million\altaffilmark{1},
Scott W. Fleming\altaffilmark{2,3},
Bernie Shiao\altaffilmark{2},
Randy Thompson\altaffilmark{2,3},
Myron Smith,
Richard L. White\altaffilmark{2},
Karen Levay\altaffilmark{2,3}}

\email{chase.million@gmail.com}
\altaffiltext{1}{Million Concepts LLC, 2204 Mountain View Ave., State College, PA 16801, USA}
\altaffiltext{2}{Space Telescope Science Institute, 3700 San Martin Dr, Baltimore, MD, 21218, USA}
\altaffiltext{3}{Computer Sciences Corporation, 3700 San Martin Dr, Baltimore, MD, 21218, USA}


\begin{abstract}
We describe the gPhoton project, an effort to calibrate, archive, and make available the complete corpus of approximately 1.8 trillion photon events individually recorded by the GALEX spacecraft. The project includes a standalone calibration pipeline which reproduces core functionalities of the GALEX mission's original calibration pipeline to lists of aspect corrected photon level data and a small suite of tools to simplify use of the photon level data with particular emphasis on short time domain analyses.  The software is freely available as an open-source application\footnote{\url{https://github.com/cmillion/gPhoton}} and will continue to be updated in the future.  We describe the set of software tools that are available, highlight differences between the gPhoton standalone calibration compared to the original mission's pipeline, and demonstrate the performance of gPhoton's calibration by analyzing standard star fluxes and measuring the pipeline's astrometric precision.  Finally, we provide a few examples of science enabled by our tools in the analyses of M flare stars, known variables, and simultaneous observations of Kepler targets.  The database will be hosted at the MAST archives and extend the utility and impact of GALEX data in the absence of dedicated, large-scale, space-based, UV-survey missions in the near future.
\end{abstract}

\section{Introduction}
The Galaxy Evolution Explorer \citep[GALEX;][]{mar2005} was a NASA Small Explorer telescope that spent approximately ten years performing an all sky survey with a 1.25 degree field-of-view in two ultraviolet (UV) bands, centered around $1528\,\rm{\AA}$ (“FUV”) and $2271\,\rm{\AA}$ (“NUV”). Each band used its own microchannel detector, while a $\rm{CaF_{2}}$ grism provided slitless spectroscopy across the entire GALEX field-of-view. The spacecraft was launched on 28 April 2003 and operated until 28 June 2013, although the FUV detector failed in May 2009. On 4 May 2010, an event occurred that is referred to as ``the Course Sun Point'' (CSP), which generated substantial streaking in the NUV detector's Y-direction. Although the effect is largely correctable through subsequent calibration and onboard adjustments, observations taken between 4 May and 23 June 2010 have reduced point spread functions. NASA support for the mission ended in February 2011. The spacecraft was then transferred to the California Institute of Technology for the “Complete the All-sky UV Survey Extension” (CAUSE) phase of the mission, during which operating costs were solicited from individuals or institutions. The GALEX mission collected data over {\color{red}some number of eclipses}, observing {\color{red}some fraction of the sky}, and accumulating {\color{red}some amount of} approximate total raw data volume and {\color{red}some other amount of} approximate reduced data volume.

The spacecraft, detectors, and calibration are well described in \citet{mor2005,mor2007}. We will attempt to restrict discussion to elements that are not discussed in those papers, have changed in the intervening years, or apply only to gPhoton.  In Section \ref{motivation} we describe the motivation behind constructing the gPhoton database and software suite.  In Section \ref{database} we describe the design and content of the $\sim 1.8$ trillion row database hosted at the Mikulski Archive for Space Telescopes (MAST).  In Section \ref{softwaretools} we describe the main programs available to use with the databse for constructing lightcurves, images, and animated data cubes.  In Section \ref{implementation} we highlight some of the implementation challenges we came across along with our our solutions, some of which may be applicable to other photon event databases.  In Section \ref{calibration} we present tests of the calibration precision by studying the astrometric, relative, and absolute fluxes produced by the software.  Finally, in Section \ref{scienceexamples}, we highlight a few example science cases enabled by gPhoton, including the study of stellar flares, high cadence lightcurves of known variables, and cross-mission science that can be conducted by combining gPhoton with data from other missions.

\section{Motivation}
\label{motivation}
Microchannel plates are non-integrating photon detectors. That is, rather than accumulating detector events in integrated bins, the microchannel plates record position and time information for every event individually. Due to computer storage and processing constraints, the GALEX mission team only released integrated maps of these data on per-observation time scales of hundreds to thousands of seconds. While the GALEX detectors were capable of recording events with a time resolution of five thousandths of a second, and a spatial resolution of {\color{red}something} on the detector, the high time and spatial resolution photon level data was not released to the community except in isolated cases by special request, and no serious attempts were made to understand the detector performance or calibration parameters for integrations shorter than about 100 seconds. Furthermore, by the end of the mission, the GALEX calibration pipeline software had grown to sufficient complexity that no attempts to get it to run outside of the GALEX network of computers at Caltech were successful. With advances in storage capacity and processing capability, we have undertaken this project to build a standalone GALEX calibration pipeline, using it to generate and archive aspect-corrected positions for the approximately $\sim\;1.8$ trillion GALEX photon events accumulated over the course of the whole mission, and a suite of software tools to make those photons usable at arbitrary spatial and temporal scales.

To avoid detector burn-in or local gain sag effects caused by depletion of electrons in the multiplier plate, the GALEX spacecraft did not stare statically at locations on the sky but continued to move over the course of each observation. Several observing patterns or “modes” were used over the course of the mission with potential consequences for the nature of the underlying data. The most basic mode was referred to as the “dither pattern” in which the spacecraft boresight would trace out a tight spiral (or “dither”) with a radius of a few arcminutes. The dither pattern was used most often for deep or medium imaging surveys in which each full eclipse of approximately 1600 seconds was spent observing a single region of the sky. In the All-sky Imaging Survey (AIS) observing mode, the spacecraft would jump between multiple positions (typically 12 “legs”) on the sky for short integrations (typically ~100 seconds) with the detector set to a non-observing state during the transition between each position, producing one independent GALEX observation (“visit”) per position. The “petal pattern” mode, used to obser brighter targets, was similar to the AIS mode except that the positions (typically 8 legs) were tightly clustered within the area of a single FOV and the detector continued to observe in the transition period. Finally, a “scan mode” was implemented late in the mission, after detector count rate limits were relaxed, and used frequently during the CAUSE phase in which the spacecraft boresight would rapidly traverse many degrees of sky at a time. Scan mode data presents unique challenges for analysis over the other modes including uncertain calibration and frequent failure of aspect refinement; while gPhoton nominally supports scan mode, that data should be used with caution.

To be clear, gPhoton is an effort to reproduce the core functionality of the GALEX mission calibration pipeline in an open source and simple to use package. The intention of the gPhoton project was never to fully reproduce the calibration capabilities of the GALEX mission pipeline, nor to anticipate and accommodate all possible science uses of the data. Rather, the intention was the create a minimal set of tools that will serve as a jumping off point for researchers to perform their own scientific analyses on the reduced data, which might include refining the GALEX calibrations entirely.

\section{Description of the Database}
\label{database}
This section will include Bernie's description of the database table, architecture, and current status of data that's loaded.

\section{Description of the Software Tools}
\label{softwaretools}
There are four utilities functions included in gPhoton and described in {\color{red}Table 1}. These utilities are all written in Python and relased under a permissive license. With the expection of gPhoton, the tools can be called either from the command line or from within the Python interpreter prompt. If called from within the interpreter, output is returned in a Python data structure.

\begin{tabular}{|p{2cm}|p{12cm}|}
\hline
	{\bf Utility} & {\bf Function}\\
	gPhoton & {Generates aspect corrected photon list files from a small set of user supplied input files which are nominally archived products of the mission pipeline. Output from gPhoton is used to populate the master photon event database hosted at MAST.}\\
	gFind & Provides information on the available data coverage for a given coordinate.\\
	gAperture & Creates lightcurves for a requested target (tables of times, calibrated fluxes, and additional parameters, with various calibrations applied).\\
	gMap & Creates calibrated count, response, or intensity maps (images) or data cubes (movies).\\
\hline
\end{tabular}

{\color{red}Table 1.}

\subsection{gPhoton}
The gPhoton standalone calibration pipeline implements only a minimum set of features from the full mission pipeline. The command line function, \textit{gPhoton.py}, accepts the raw scientific data file (raw6), the spacecraft state file (scst), and a refined aspect file (asprta), and returns a table in comma-separated-value (csv) format in which each row corresponds to a detector event and contains both raw and aspect-corrected detector positions, as well as sky positions and a number of intermediate detector parameters. The raw6, scst, and asprta files are products of the mission calibration pipeline that are archived at MAST {\color{red}Is it true that all of these are already archived?}. The raw6 and scst files are products of the ingest stage of the mission pipeline and simply contain parsed subsets of data that was originally in the raw spacecraft telemetry files (tlms). While the scst files contain many parameters related to spacecraft status, including the coarse estimated boresight pointing from the star tracker, only a single temperature value from the scst is used for the purpose of applying a temperature dependent plate scale correction. The asprta files, products of the aspect correction stage of the mission pipeline, contain refined boresight pointing estimates on a per-second basis, created by iteratively comparing 15-second depth intensity maps generated from the best-available aspect solution against star catalogs. By using these mission products directly, we do not need to recreate the ingest or aspect correction stages of the mission calibration pipeline.

In most cases, a flag column entries which is not equal to zero indicates that an event could not be aspect corrected for some reason. One exception is events which are flagged because they fall within a gap in the refined aspect solution during which the detector continue to observe (for example, between legs of a petal pattern observation); in such cases, the events are aspect corrected but flagged as having unreliable aspect solutions. Another exception is events which fall within regions of the detector known to be sources of hotspots which can be aspect corrected but should not be naively trusted. Events which are not aspect correctable for some reason (for example, those arising from the detector stims) are referred to as “null” data because they contain null values in the right ascension and declination columns of the photon list file. Null data can be useful for detector calibration and, in particular, exposure time correction based upon the stim or global count rates. Other than hotspots, the gPhoton project does not implement any artifact flagging or masking.

\subsection{gFind}
This utility provides a mechanism for the user to inspect the available data coverage for a particular target. Given a target position, it will return the estimated (raw) depth of available data over the whole mission, as well as the time ranges for specific observations in which these data are contained. Rather than using the visit-based bookkeeping of the mission logs to determine the available coverage of a specific location on the sky, \textit{gFind} attempts to use the data itself. A position on the sky is considered to be covered during time ranges in which it falls within half a detector diameter (an adjustable parameter with a default of 1.25 degrees) of the boresight center, as defined by the refined aspect solution (asprta). The contiguity of data for the purposes of grouping them into discrete time ranges is defined by a user adjustable parameter that defines the maximum gap allowed for data to be considered part of the same obvservation. There is a similar user-adjustable parameter that defines the minimum exposure depth considered to be a valid exposure.

\subsection{gAperture}
This utility performs photometric analysis given a target position, aperture radius, optional inner and outer radii of a background annulus, and optional time ranges. Simple aperture photometry is used, but the fact that the aspect corrected photon-level data is available allows us to perform a cone search on the data to precisely count the number of photons within the aperture rather than binning the photons into pixels--sacrificing spatial precision in the process--and then performing interpolations as would be done for normal integrated image data. The background counts are similarly computed. Rather than integrating a relative response map, the photon events can be individually weighted by using their detector positions to sample the flat directly. Effective exposure times (raw exposure time modified by effects of data dropouts and detector deadtime) are estimated from the count rates over the entire detector. The photometry can be computed within any time bin, up to and including an integration over the entire mission. The output format is a comma separated value format file containing a large number of columns which include raw counts, background rates, estimated errors, mean response over the aperture, and mean time of arrival for photon events within the time bin. When gPhoton is called from within the Python interpreter, the returned data structure contains a large number of additional parameters including the complete photon list data for the targeted region of the sky, permitting detailed analysis.

\subsection{gMap}
This utility generates integrated count, response, and intensity image maps for targeted regions and time ranges. All image data is written in the Flexible Image Transport System (FITS) with headers populated using World Coordinate System standards. Count (cnt) images are integrated images which have not been scaled by the detector response, generated by performing a box search for events in the requested region and then binning the events into pixels with the same spatial dimensions as products generated by the mission. High resolution relative response (rrhr) maps are created by adding successive projections of the detector flat onto the sky, using the boresight position, at one second intervals, scaled by effective exposure time. Intensity (int) maps are the "calibrated" image products from which photometric analyses may be performed, are simply count maps divided by relative response maps.

The images produced by gMap are analogous to the imaging data products produced by the mission pipeline and archived at MAST with the exceptions that users are not limited to images with specific dimensions and coadds can be created arbitrarily across visits and surveys. Also, each of these types of images can also be generated as data cubes or movie files with user specified time bins whereas full resolution and calibrated movie files were never available from the mission. Note that because the gnomonic projection used by GALEX increasingly distorts images near the poles, you can expect images generated by \textit{gMap} to, in general, not have the same aspect ratio in pixels as they have in degrees.

\section{Implementation Challenges and Solutions}
\label{implementation}
Numerous challenges have arisen during the development of this project, and our solutions to some of these may be helpful to other microchannel plate or photon level data investigations. The details may be of general interest to users of our software suite as well.

\subsection{Photon Level Analysis}

\subsection{Effective Exposure Time Calculation}
The exposure time correction and, in particular, the global dead time correction, was not reliable for short time ranges. This is because the dead time correction was computed in the original mission pipeline by comparing the measured stim rate against the nominal stim rate of 79 counts per second. At short time ranges (on the order of seconds), the variance in this rate due simply to Poissonian counting statistics made the error in the exposure time calculation sufficiently high as to make flux calculations meaningless. The solution was to use the empirical dead time correction, a linear fitted relationship of dead time as a function of the global detector count rate (which can be thousands of counts per second). Our tests have shown that this is a reliable estimator of the dead time correction and leads to stable/reliable effective exposure times at short time ranges.

\subsection{Background Correction}
In order to increase the reliability of the background correction, we’ve implemented a ``swiss cheese'' algorithm that masks out known sources within the annulus.  The count rate within the effective area of the annulus following the ``swiss cheese'' masking is then scaled to the area of the aperture.

\subsection{Relative Response Correction}
The relative response (i.e. flat field) was not characterized at spatial resolutions that make it meaningful for short time domains. That is, because the detector is constantly in motion with respect to the sky during any observation, any given source samples a region of the detector. The resolution chosen for the flat field (approximately equal to the width of a single ``dither'') was chosen with the assumption that an integrated observation would smear out any sub-resolution detector response effects, and the uncertainties would average out. This assumption does not hold for short exposure times. We have no solution for this, and it continues to be a problem. but we know of efforts by other investigators to characterize the flat at higher spatial resolutions.  This is one area that may be improved with future versions of our software.

\subsection{Flux Uncertainties}
{\color{red}We are going to need to explain the current way the pipeline estimates uncertainty, some of the challenges with deriving an accurate uncertainty estimate, and perhaps some ideas for improvements in the future.}
{\color{red}Note: Include a plot of LDS 749B vs. effective exposure time, like Chase has made, and comment.}

\section{Calibration Tests}
\label{calibration}

\subsection{Astrometric Solutions}
{\color{red}I'm not sure what the best tests here are, other than to trace the photocenters of objects across time?}

\subsection{Relative Flux Precision}
{\color{red}Here is where we will take a bunch of plates and study the variability as a function of distance from plate center, working under the assumption that most non-extended sources should be constant within their uncertainties.}

\subsection{Absolute Flux Precision}
We have made use of the same white dwarf standard stars that were used by the GALEX mission pipeline to help calibrate and test our absolute flux precision.  Specifically, we use the white dwarf stars LDS 749B {\color{red}What are the other ones?}.

{\color{red}Note: Include as many white dwarfs from Camarota \& Holberg 2014 as possible to compare their final fluxes and ours.}

\section{Example Science Applications}
\label{scienceexamples}

\subsection{Flare Stars}

\subsection{Cross-Mission Overlap}

\section{Conclusion}
The GALEX data set has already proven to be extremely productive and is likely to be one of the most influential ultraviolet astronomical surveys for the foreseeable future. The gPhoton project simplifies, and in some cases enables, analyses using this data that were previously difficult or impossible, especially those related to short time domain photometry. While the gPhoton project is an effort to calibrate and make available the GALEX photon level data specifically, some of the techniques described here can be applicable to other observational databases that make use of non-integrating detectors, particularly microchannel plates. The fact that spatial analyses can be performed by making direct cuts on the photon level data rather than artificially degrading the spatial components of the data by integrating and interpolating onto image maps offers potential advantages in terms of both the flexibility of the data archive and the computational cost of analysis. The corresponding data management and volume issues associated with storing and retrieving massive amounts of photon level data is non-trivial, but also entirely soluble with appropriate use of existing database and storage technology. The behavior of the GALEX detector during very short timespans (which correspond to very small spatial sampling of the detector) is not well characterized, and further work on improving the resolution of the detector response, as well as correctly propagating flux uncertainties, will be required to derive the maximum utility from the photon level data.

\acknowledgements
Place acknowledgements here.

\begin{thebibliography}{}
\bibitem[Martin et al.(2005)]{mar2005} Martin, D.~C., Fanson, J., Schiminovich, D., et al.\ 2005, \apjl, 619, L1
\bibitem[Morrissey et al.(2005)]{mor2005} Morrissey, P., Schiminovich, D., Barlow, T.~A., et al.\ 2005, \apjl, 619, L7
\bibitem[Morrissey et al.(2007)]{mor2007} Morrissey, P., Conrow, T., Barlow, T.~A., et al.\ 2007, \apjs, 173, 682
\end{thebibliography}

%%%%%%%%%%%%%%%%%% tables here %%%%%%%%%%%%%%%%%%

\clearpage

%%%%%%%%%%%%%%%%%% end tables %%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%% figures here %%%%%%%%%%%%%%%%%%

\clearpage

%%%%%%%%%%%%%%%%%% end figures %%%%%%%%%%%%%%%%%%

\end{document}
